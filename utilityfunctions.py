# -*- coding: utf-8 -*-
"""UtilityFunctions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MEoj84YR2oPsMUAnO_TZ66lx8i_eIaZ-
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import json
from pandas.io.json import json_normalize
from datetime import datetime
from sklearn.preprocessing import LabelEncoder,OneHotEncoder
from scipy.sparse import hstack
from sklearn.preprocessing import StandardScaler
from sklearn.externals import joblib

def load_json_data(df,df_column_name):
 unnormalized=[]# it will be list of dictionaries
 list_values=(list(df[df_column_name].values))
 for i in list_values:
     unnormalized.append(json.loads(i))# to parse the json string , result will be python dictionary
 return unnormalized

def flatten_json_data(unnormalized):
 normalized=json_normalize(unnormalized)
 return normalized

def date_process(df):
    df["date"] = pd.to_datetime(df["date"], format="%Y%m%d") # seting the column as pandas datetime
    df["_weekday"] = df['date'].dt.weekday #extracting week day
    df["_day"] = df['date'].dt.day # extracting day
    df["_month"] = df['date'].dt.month # extracting day
    df["_year"]=df['date'].dt.year # extracting day
    df['_visitHour'] = df['visitStartTime'].apply(lambda x: str(datetime.fromtimestamp(x).hour)).astype(int)
    
    return df #returning the df after the transformations

def preprocessing(raw_data):
  #flatten json columns
  JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']
  for column in JSON_COLUMNS:
    listofdicts=load_json_data(raw_data,column)
    flattened_json_column=flatten_json_data(listofdicts)
    if column=='device':
      device_df_test=flattened_json_column
    elif column=='geoNetwork':
      geoNetwork_df_test=flattened_json_column
    elif column=='totals':
      totals_df_test=flattened_json_column
    elif column=='trafficSource':
      trafficSource_df_test=flattened_json_column 

  raw_data.drop(JSON_COLUMNS,axis=1,inplace=True)
  data_wo_json=pd.concat([raw_data,device_df_test,geoNetwork_df_test,totals_df_test,trafficSource_df_test],axis=1)

  #Remove features which are not gonna help in prediction
  cardinality_one=['socialEngagementType','browserVersion','browserSize','operatingSystemVersion','mobileDeviceBranding','mobileDeviceModel','mobileInputSelector','mobileDeviceInfo','mobileDeviceMarketingName','flashVersion','language','screenColors','screenResolution','cityId','latitude','longitude','networkLocation','visits','bounces','newVisits','adwordsClickInfo.criteriaParameters','isTrueDirect','adwordsClickInfo.isVideoAd']
  data_wo_json.drop(cardinality_one,axis=1,inplace=True)

  # replace missing values with NaN
  data_wo_json.replace("not available in demo dataset",np.nan,inplace=True)
  data_wo_json.replace("(not set)",np.nan,inplace=True)
  data_wo_json.replace("(not provided)",np.nan,inplace=True)
  data_wo_json.replace("unknown.unknown",np.nan,inplace=True)

  return data_wo_json

def feature_engineering(data):
  # Feature engineering of date column
  engineered_data=date_process(data)
  return engineered_data

def Column_label_encoding(categorical_feature,engineered_data):
  path_of_saved_LabelEncoder="drive/My Drive/GA_customer_revenue_prediction/label_encoder_"+categorical_feature+".pkl"
  le =joblib.load(path_of_saved_LabelEncoder)
  label_encoded_feature=le.transform(list(engineered_data[categorical_feature].values.astype('str')))
  return label_encoded_feature

def Featurization(engineered_data):
  #Featurization
  #drop_list=['sessionId','visitId','adwordsClickInfo.gclId','adwordsClickInfo.adNetworkType']
  #engineered_data.drop(drop_list,axis=1,inplace=True)
  Categorical_columns=['channelGrouping','browser', 'operatingSystem', 'isMobile', 'deviceCategory', 'continent',
       'subContinent', 'country', 'region', 'metro', 'city','networkDomain',
        'campaign','source', 'medium', 'keyword','referralPath','adwordsClickInfo.slot','adContent']
  Numerical_columns=['visitNumber','hits', 'pageviews','sessionQualityDim','timeOnSite','transactions','adwordsClickInfo.page']
  encoded_categorical_col=['_weekday', '_day', '_month', '_year', '_visitHour']

  encoded_data=pd.DataFrame()
  for feature in Categorical_columns:
    encoded_data[feature]=Column_label_encoding(feature,engineered_data)

  #One hot encoder only takes numerical categorical values, hence any value of string type should be label encoded before one hot encoded. 
  one_hot=joblib.load("drive/My Drive/GA_customer_revenue_prediction/one_hot_encoder.pkl")
  cat_sparse=one_hot.transform(encoded_data)  

  Numerical_data=engineered_data[Numerical_columns]
  scaler = StandardScaler()
  Standardize_numeric_data=scaler.fit_transform(Numerical_data)

  df_numeric_data=pd.DataFrame(Standardize_numeric_data)
  date_data=engineered_data[encoded_categorical_col]
  final_one=hstack((cat_sparse,df_numeric_data,date_data))
  
  return final_one

def predict_revenue(encoded_data,fullVisitorId):
  model=joblib.load("drive/My Drive/GA_customer_revenue_prediction/stored_model1.pkl")
  test_predictions=model.predict(encoded_data,num_iteration=model.best_iteration)
  results=pd.DataFrame({"fullVisitorId":fullVisitorId})
  test_predictions[test_predictions<0]=0
  results["PredictedLogRevenue"]=np.expm1(test_predictions)
  final_output=results.groupby("fullVisitorId").agg({"PredictedLogRevenue":"sum"}).reset_index()
  final_output.columns=["fullVisitorId","PredictedLogRevenue"]
  final_output["PredictedLogRevenue"]=np.log1p(final_output["PredictedLogRevenue"])
  return final_output

def predict_revenue_target_given(encoded_data,fullVisitorId,target_values):
  model=joblib.load("drive/My Drive/GA_customer_revenue_prediction/stored_model1.pkl")
  test_predictions=model.predict(encoded_data,num_iteration=model.best_iteration)
  results=pd.DataFrame({"fullVisitorId":fullVisitorId})
  test_predictions[test_predictions<0]=0
  results["PredictedLogRevenue"]=np.expm1(test_predictions)
  # we also have true labels
  results["True_labels"]=target_values
  final_output=results.groupby("fullVisitorId").agg({"PredictedLogRevenue":"sum","True_labels":"sum"}).reset_index()
  final_output.columns=["fullVisitorId","PredictedLogRevenue","True_labels"]
  final_output["PredictedLogRevenue"]=np.log1p(final_output["PredictedLogRevenue"])
  return final_output